{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11wLFBJ9K9kC"
   },
   "source": [
    "## Vamos iniciar nosso notebook chamando todas as bibliotecas que usaremos. Nessa etapa, nada precisa ser modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o68CyQHsK9kC",
    "outputId": "bc53a15a-d895-4ec5-ff1b-357bb5403dbc"
   },
   "outputs": [],
   "source": [
    "!pip install arrow bokeh paho.mqtt -q\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session\n",
    "import pprint\n",
    "import numpy as np\n",
    "import arrow\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from threading import Timer\n",
    "\n",
    "#Url de publicacao dos dados\n",
    "pub_url = 'https://data.demo.konkerlabs.net/pub/'\n",
    "#Url da API\n",
    "base_api = 'https://api.demo.konkerlabs.net'\n",
    "#Application padrão\n",
    "application = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Xx5-L6LK9kG"
   },
   "outputs": [],
   "source": [
    "# Credenciais do usuário da Plataforma\n",
    "username = ''\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "os4JmWszK9kG"
   },
   "outputs": [],
   "source": [
    "device_name = \"Cloud\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llXJZavfK9kI"
   },
   "source": [
    "## Usando a API da Konker para obter os dados e analisa-los localmente\n",
    "Para iniciar esse trabalho, vamos primeiro conectar na API da Konker. A API usa OAuth2, então primeiro vamos obter as credenciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvBPWrj9K9kI"
   },
   "outputs": [],
   "source": [
    "client = BackendApplicationClient(client_id=username)\n",
    "oauth = OAuth2Session(client=client)\n",
    "token = oauth.fetch_token(token_url='{}/v1/oauth/token'.format(base_api),\n",
    "                                       client_id=username,\n",
    "                                       client_secret=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElQLe5QqK9kJ",
    "outputId": "5a4fe752-56ee-4de7-8f7e-66d0b56cbefd"
   },
   "outputs": [],
   "source": [
    "devices = oauth.get(\"https://api.demo.konkerlabs.net/v1/{}/devices/\".format(application)).json()['result']\n",
    "for dev in devices:\n",
    "    print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgHLMiR6K9kJ"
   },
   "source": [
    "Vamos procurar pelo dispositivo Cloud na sua lista de dispositivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pQ1Z7V0K9kJ",
    "outputId": "467559a6-aef1-48eb-ff26-136d4cab639e"
   },
   "outputs": [],
   "source": [
    "guid_dev=\"\"\n",
    "for dev in devices:\n",
    "    if dev['name'] == device_name:\n",
    "        guid_dev = dev['guid']\n",
    "\n",
    "print(\"O GUID do dispositivo é: \"+ guid_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h_FFEksK9kJ"
   },
   "source": [
    "Caso você consiga ver o GUID do dispositivo, significa que está tudo funcionando bem. Caso o GUID não apareça, revise o nome do dispositivo no Notebook e o nome escolhido na plataforma para garantir que eles possuem a mesma grafia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Cq4FK4BK9kK",
    "outputId": "0950b296-5792-4306-f68b-09c9c7cba4dd"
   },
   "outputs": [],
   "source": [
    "dt_start = arrow.utcnow().to('America/Sao_Paulo').floor('day')\n",
    "dt_start = dt_start.shift(days=-20)\n",
    "stats = oauth.get(\"https://api.demo.konkerlabs.net/v1/{}/incomingEvents?q=device:{} timestamp:>{}&sort=oldest&limit=10000\".format(application,guid_dev,dt_start.isoformat())).json()['result']\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "Esv5cPnCK9kK",
    "outputId": "5982050b-013f-4d66-ece4-d33fef01e093"
   },
   "outputs": [],
   "source": [
    "stats_df = pd.json_normalize(stats).set_index('timestamp')\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6NHPL6RM9iA"
   },
   "source": [
    "Agora você pode trabalhar com os dados no formato tabular, separando os dados de cada experimento separadamente.Cada dado está em um canal:\n",
    "\n",
    "Experimento 1: \"temperature\"<br />\n",
    "Experimento 2: \"mnist\"<br />\n",
    "Experimento 3: \"dogcat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mh4-mF9pM_bb"
   },
   "outputs": [],
   "source": [
    "temperature = stats_df[stats_df['incoming.channel']=='temperature']\n",
    "mnist = stats_df[stats_df['incoming.channel']=='mnist']\n",
    "dogcat = stats_df[stats_df['incoming.channel']=='dogcat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IedlALw7C96h"
   },
   "source": [
    "Vamos tomar como exemplo a primeira aplicação, pois as variáveis são basicamente as mesmas em todas as demais. Na primeira aplicação temos as variáveis:\n",
    "\n",
    "**_ts**: timestamp de chegada do dado na plataforma de IoT; </br >\n",
    "**edge_ts**: timestamp da saída do dado do servidor de borda; </br >\n",
    "**cloud_latency**: tempo de execução da inferência na nuvem (ms); </br >\n",
    "**edge_latency**: tempo de execução da inferência na borda (ms);</br >\n",
    "**dev_latency**:tempo de execução no dispositivo (ms) - Essa variável só existe nessa aplicação, pois o KMeans pode ser executado no dispostivivo.\n",
    "\n",
    "A ideia desse laboratório é calcular onde é mais benéfico rodar a aplicação de Aprendizado de Máquina testada, supondo que a inferência deve ser enviada de volta para o dispositivo (logo deve-se somar o tempo borda->nuvem e nuvem->borda que vamos assumir serem idênticos). Suponha também que a latência entre o dispositivo e a borda seja desprezível. Dessa forma, para que seja benéfico rodar na nuvem, a condição seria:\n",
    "\n",
    "cloud_latency+2$*$(_ts - edge_ts - cloud_latency) < edge_latency </br >\n",
    "cloud_latency+2$*$(_ts - edge_ts - cloud_latency) < dev_latency\n",
    "\n",
    "Da mesma forma, para que seja benéfico rodar na borda, temos a condição:\n",
    "\n",
    "edge_latency < cloud_latency+2$*$(_ts - edge_ts - cloud_latency) </br >\n",
    "edge_latency < dev_latency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b46bA6IRHauH"
   },
   "outputs": [],
   "source": [
    "#Nesse exemplo, estou usando apenas os últimos 10 pontos, por questão de estabilidade do Google Colab (antes disso a latência era ordens de magnitude maior). Recomendo que vocês testem essa variável.\n",
    "\n",
    "app1_cloud = (2*(temperature['payload._ts'][-10:] - temperature['payload.edge_ts'][-10:]) - temperature['payload.cloud_latency'][-10:]).mean()\n",
    "app1_edge = (temperature['payload.edge_latency'][-10:]).mean()\n",
    "app1_dev = (temperature['payload.dev_latency'][-10:]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5canF1eFIMq1",
    "outputId": "1701823b-961b-43e3-93b1-f905e5141005"
   },
   "outputs": [],
   "source": [
    "print('Tempo total para inferência na Nuvem: ' + str(app1_cloud)+ ' ms')\n",
    "print('Tempo total para inferência na Borda: ' + str(app1_edge)+ ' ms')\n",
    "print('Tempo total para inferência no Dispotivo: ' + str(app1_dev)+ ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjuTiUf6GAEi"
   },
   "source": [
    "Após calcular qual a melhor camada para rodar cada uma das três aplicações de Aprendizado de Máquina, descreva em um relatório sua resposta e se esse era o resultado que você esperaria. Discuta se as soluções encontradas fazem sentido para você. Adicione no relatório também uma explicação a respeito de como foi feita a montagem do experimento, ou seja, qual o equipamento utilizado, como foi conectado e o código que você utilizou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hB-o07izAlMG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
